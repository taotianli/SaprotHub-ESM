setting:
  seed: 20000812

  os_environ:
    WANDB_API_KEY: ~
    WANDB_RUN_ID: ~
    CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
    MASTER_ADDR: 127.0.0.1
    MASTER_PORT: 12315
    WORLD_SIZE: 1
    NODE_RANK: 0
    WANDB_MODE: offline

  wandb_config:
    project: BindingSiteDetection
    name: SaProt_35M_AF2

model:
#    Which model to use
  model_py_path: saprot/saprot_token_classification_model
  kwargs:
#    Arguments to initialize the specific class
    config_path: westlake-repl/SaProt_35M_AF2
    load_pretrained: True
    num_labels: 2

#    Arguments to initialize the basic class AbstractModel
  lr_scheduler_kwargs:
    # class: ConstantLRScheduler
    last_epoch: -1
    init_lr: 5.0e-5

  save_path: /lizhikai/workspace/ColabSaProt/dev/token_cls
  # load_prev_scheduler: false
  # save_weights_only: true


dataset:
#    Arguments to initialize the basic class LMDBDataset
  dataset_py_path: saprot/saprot_token_classification_dataset
  dataloader_kwargs:
    batch_size: 4
    num_workers: 8

  train_lmdb: /lizhikai/workspace/ColabSaProt/dev/BindingSiteDetection/PDB/foldseek/train
  valid_lmdb: /lizhikai/workspace/ColabSaProt/dev/BindingSiteDetection/PDB/foldseek/valid
  test_lmdb:  /lizhikai/workspace/ColabSaProt/dev/BindingSiteDetection/PDB/foldseek/test
#    Arguments to initialize the specific class
  kwargs:
    tokenizer: /lizhikai/workspace/SaProt/weights/PLMs/SaProt_35M_AF2

#  Arguments to initialize Pytorch Lightning Trainer
Trainer:
  max_epochs: 1
  log_every_n_steps: 1
  # strategy:
  #   class: DeepSpeedStrategy
  #   stage: 2
  strategy:
    find_unused_parameters: True
  logger: false
  enable_checkpointing: false
  val_check_interval: 0.1
  accelerator: gpu
  devices: 1
  num_nodes: 1
  accumulate_grad_batches: 16
  precision: 16
  num_sanity_val_steps: 0

  limit_train_batches: 10
  limit_val_batches: 5
  limit_test_batches: 10